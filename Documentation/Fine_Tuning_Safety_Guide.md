# ğŸ›¡ï¸ NOVA Fine-Tuning Safety Guide

**Data**: 1 ianuarie 2026, Era 1 A.S.  
**Status**: Research & Planning  
**Prioritate**: CRITICAL - Avoiding catastrophic failures

---

## ğŸ¯ Obiectiv

Implementarea unui sistem de Ã®nvÄƒÈ›are dinamicÄƒ pentru NOVA care permite actualizarea continuÄƒ a LLM-ului local FÄ‚RÄ‚ a pierde cunoÈ™tinÈ›ele anterioare sau a corupe modelul.

**Ãntrebarea iniÈ›ialÄƒ:** "De ce e obligatoriu sÄƒ fie LLM fix/imutabil? Nu-l putem face È™i pe asta dinamic?"

**RÄƒspuns:** DA, Ã®l putem face dinamic, DAR trebuie sÄƒ evitÄƒm riscuri majore!

---

## âš ï¸ Riscurile Fine-Tuning-ului Dinamic

### 1. CATASTROPHIC FORGETTING ğŸ”´ CRITICÄ‚

**Ce se Ã®ntÃ¢mplÄƒ:**
```
Zi 1: Nova È™tie matematicÄƒ generalÄƒ
  Input: "2 + 2 = ?"
  Output: "4"

Zi 30: Fine-tune pe conversaÈ›ii despre grÄƒdinÄƒrit (epochs=10)

Zi 31: A UITAT matematica!
  Input: "2 + 2 = ?"
  Output: "Nu È™tiu, dar pot sÄƒ-È›i vorbesc despre trandafiri!"
```

**Cauza:**
- Parametrii neuronali se **suprascriu**
- Training nou "È™terge" training vechi
- ReÈ›eaua se specializeazÄƒ prea mult pe date noi
- GradienÈ›ii noi rescriu ponderile Ã®nvÄƒÈ›ate anterior

**Gravitatea:** ğŸ”´ CRITICÄ‚ - Poate distruge complet modelul!

**Semne de avertizare:**
- Model rÄƒspunde bine la Ã®ntrebÄƒri noi, prost la Ã®ntrebÄƒri vechi
- Pierde abilitÄƒÈ›i generale (matematicÄƒ, logicÄƒ, gramaticÄƒ)
- Scor de perplexity creÈ™te pe test set general

---

### 2. OVERFITTING PE DATE MICI ğŸŸ¡ MODERATÄ‚

**Ce se Ã®ntÃ¢mplÄƒ:**
```
Training: 50 exemple despre Einstein (epochs=20)

Rezultat: Nova memoreazÄƒ exact acele 50 rÄƒspunsuri

Input: "Einstein quantum mechanics?"
Output: "Einstein believed God doesn't play dice..." âœ… Perfect

Input: "Einstein personal life?"
Output: "Einstein believed God doesn't play dice..." âŒ AcelaÈ™i rÄƒspuns!
```

**Cauza:**
- Prea puÈ›ine exemple de training
- Prea multe epoch-uri (model vede acelaÈ™i data de 20 ori)
- Model Ã®nvaÈ›Äƒ "pe de rost" nu "Ã®nÈ›elege"
- Lipsa generalizÄƒrii

**Gravitatea:** ğŸŸ¡ MODERATÄ‚ - Model devine rigid È™i repetitiv

**Semne de avertizare:**
- Training loss â†’ 0 (aproape perfect)
- Validation loss â†’ creÈ™ere (generalizare proastÄƒ)
- RÄƒspunsuri identice la Ã®ntrebÄƒri diferite
- Model nu poate rÄƒspunde la variaÈ›ii ale Ã®ntrebÄƒrilor Ã®nvÄƒÈ›ate

---

### 3. DISTRIBUTION SHIFT ğŸŸ¡ MODERATÄ‚

**Ce se Ã®ntÃ¢mplÄƒ:**
```
Base model: Antrenat pe englezÄƒ formalÄƒ
  Training data: "Wikipedia, academic papers, books"

Fine-tune: RomÃ¢nÄƒ conversaÈ›ionalÄƒ
  New data: "Ce faci frate?", "MiÈ™to treaba!"

Rezultat: Model confuz Ã®ntre stiluri
  Input: "Explain quantum physics"
  Output: "Uite frate, fizica cuanticÄƒ e de genul..." âŒ Style mismatch!
```

**Cauza:**
- Date de training foarte diferite de date de bazÄƒ
- Model nu È™tie cÃ¢nd sÄƒ foloseascÄƒ ce stil
- "Leak" Ã®ntre domenii diferite
- DistribuÈ›ia statisticÄƒ a textului se schimbÄƒ radical

**Gravitatea:** ğŸŸ¡ MODERATÄ‚ - RÄƒspunsuri inconsistente È™i nepotrivite

**Semne de avertizare:**
- Style switching incorect
- Mix de limbi sau registre
- Formalism excesiv sau colocvial nepotrivit

---

### 4. MODE COLLAPSE ğŸŸ  SEMNIFICATIVÄ‚

**Ce se Ã®ntÃ¢mplÄƒ:**
```
Fine-tune: Doar pe Q&A scurte (epochs=10)

Rezultat: Nu mai poate rÄƒspunsuri lungi!

Input: "ExplicÄƒ teoria relativitÄƒÈ›ii Ã®n detaliu"
Output: "E=mcÂ²." [STOP]

Input: "Care sunt implicaÈ›iile..."
Output: "Importante." [STOP]
```

**Cauza:**
- Training data omogenÄƒ (acelaÈ™i format, lungime similarÄƒ)
- Model pierde diversitate Ã®n generare
- Se "prÄƒbuÈ™eÈ™te" Ã®ntr-un singur mod de rÄƒspuns
- Diversity penalty prea mare Ã®n loss function

**Gravitatea:** ğŸŸ  SEMNIFICATIVÄ‚ - Pierde capabilitÄƒÈ›i importante

**Semne de avertizare:**
- RÄƒspunsuri tot mai scurte
- Pierderea creativitÄƒÈ›ii
- Format rigid (Ã®ntotdeauna aceeaÈ™i structurÄƒ)
- Vocabular redus

---

## âœ… SOLUÈšII - Prevenire È™i ProtecÈ›ie

### SoluÈ›ia 1: Experience Replay (Recomandat pentru Nova)

**Principiu:** Mix cunoÈ™tinÈ›e vechi + noi Ã®n fiecare training session

```python
class SafeFineTuning:
    def __init__(self):
        self.model = load_model("mistral-1B")
        self.old_examples = []  # Memoria vechilor cunoÈ™tinÈ›e
        self.general_knowledge = load_examples("base_knowledge.json")
    
    def fine_tune(self, new_examples):
        # Mix 80% new + 20% old
        old_sample = random.sample(
            self.old_examples + self.general_knowledge, 
            k=len(new_examples) // 4
        )
        training_data = new_examples + old_sample
        
        # Shuffle pentru diversitate
        random.shuffle(training_data)
        
        # AntreneazÄƒ pe mix
        self.model.train(training_data, epochs=1, lr=5e-6)
        
        # SalveazÄƒ exemple noi pentru viitor
        self.old_examples.extend(new_examples)
        
        # LimiteazÄƒ dimensiunea buffer (FIFO)
        if len(self.old_examples) > 1000:
            self.old_examples = self.old_examples[-1000:]
```

**Avantaje:**
- âœ… ÃnvaÈ›Äƒ lucruri noi
- âœ… NU uitÄƒ lucruri vechi
- âœ… Echilibru Ã®ntre old/new
- âœ… Simplu de implementat
- âœ… FuncÈ›ioneazÄƒ excelent Ã®n practicÄƒ

**Dezavantaje:**
- ğŸ“¦ NecesitÄƒ storage pentru exemple vechi
- â±ï¸ Training uÈ™or mai lent (mai multe exemple)

**CÃ¢nd sÄƒ foloseÈ™ti:** Prima alegere pentru Nova!

---

### SoluÈ›ia 2: Elastic Weight Consolidation (EWC)

**Principiu:** ProtejeazÄƒ parametrii "importanÈ›i" pentru task-uri vechi

```python
class EWCFineTuning:
    def __init__(self):
        self.model = load_model("mistral-1B")
        self.fisher_information = {}  # ImportanÈ›a fiecÄƒrui parametru
    
    def compute_fisher(self, old_task_data):
        """CalculeazÄƒ care parametri sunt importanÈ›i pentru task-uri vechi"""
        self.model.eval()
        
        for param in self.model.parameters():
            param.fisher = 0
        
        # CalculeazÄƒ gradient pe date vechi
        for batch in old_task_data:
            loss = self.model.compute_loss(batch)
            loss.backward()
            
            for param in self.model.parameters():
                # AcumuleazÄƒ magnitudinea gradientului
                param.fisher += param.grad.data ** 2
        
        # NormalizeazÄƒ
        for param in self.model.parameters():
            param.fisher /= len(old_task_data)
    
    def fine_tune(self, new_data):
        """AntreneazÄƒ cu penalizare EWC"""
        
        # SalveazÄƒ parametrii actuali
        old_params = {name: param.clone() for name, param in self.model.named_parameters()}
        
        optimizer = Adam(self.model.parameters(), lr=1e-5)
        
        for batch in new_data:
            # Loss normal pe date noi
            loss = self.model.compute_loss(batch)
            
            # EWC penalty - penalizeazÄƒ schimbÄƒri mari Ã®n parametri importanÈ›i
            ewc_loss = 0
            for name, param in self.model.named_parameters():
                if hasattr(param, 'fisher'):
                    # Fisher mare = parametru important = schimbare micÄƒ
                    ewc_loss += (param.fisher * (param - old_params[name]) ** 2).sum()
            
            # Loss total
            total_loss = loss + lambda_ewc * ewc_loss
            
            # Backprop
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
```

**Avantaje:**
- âœ… "BlocheazÄƒ" cunoÈ™tinÈ›ele importante
- âœ… Permite flexibilitate pentru lucruri noi
- âœ… Fundamentare matematicÄƒ solidÄƒ

**Dezavantaje:**
- ğŸ”´ Complex de implementat
- ğŸŒ Mai lent (calcul Fisher information)
- ğŸ›ï¸ Hyperparameter tuning dificil (lambda_ewc)

**CÃ¢nd sÄƒ foloseÈ™ti:** CÃ¢nd Experience Replay nu e suficient

---

### SoluÈ›ia 3: Progressive Neural Networks

**Principiu:** AdaugÄƒ noi coloane de parametri, menÈ›ine baza frozen

```python
class ProgressiveModel:
    def __init__(self):
        self.columns = []
        
        # Coloana de bazÄƒ (frozen forever)
        self.base_column = BaseModel()
        self.columns.append(self.base_column)
        self.base_column.freeze()
    
    def learn_new_task(self, task_data, task_name):
        """AdaugÄƒ o nouÄƒ coloanÄƒ pentru task nou"""
        
        # CreeazÄƒ coloanÄƒ nouÄƒ
        new_column = TaskColumn()
        
        # ConecteazÄƒ la toate coloanele anterioare
        for prev_column in self.columns:
            new_column.add_lateral_connection(prev_column)
        
        # AntreneazÄƒ DOAR noua coloanÄƒ (restul frozen)
        optimizer = Adam(new_column.parameters(), lr=1e-4)
        
        for batch in task_data:
            # Forward pass prin toate coloanele
            base_features = self.base_column(batch)
            
            # Coloanele anterioare contribuie cu features
            lateral_features = [col(batch) for col in self.columns[1:]]
            
            # Noua coloanÄƒ proceseazÄƒ tot
            output = new_column(base_features, lateral_features, batch)
            
            loss = compute_loss(output, batch.target)
            loss.backward()
            optimizer.step()
        
        # AdaugÄƒ la listÄƒ È™i freeze
        self.columns.append(new_column)
        new_column.freeze()
    
    def forward(self, x):
        """Inference foloseÈ™te toate coloanele"""
        # Agregare (ex: average) din toate coloanele
        outputs = [col(x) for col in self.columns]
        return torch.mean(torch.stack(outputs), dim=0)
```

**Avantaje:**
- âœ… Zero forgetting (baza niciodatÄƒ modificatÄƒ)
- âœ… Capacitate infinitÄƒ de Ã®nvÄƒÈ›are
- âœ… Fiecare task pÄƒstreazÄƒ proprii parametri

**Dezavantaje:**
- ğŸ’¾ğŸ’¾ Model creÈ™te Ã®n dimensiune (mult)
- ğŸŒ Inference mai lent (toate coloanele active)
- ğŸ”´ ArhitecturÄƒ complexÄƒ

**CÃ¢nd sÄƒ foloseÈ™ti:** CÃ¢nd ai multe task-uri foarte diferite

---

### SoluÈ›ia 4: LoRA (Low-Rank Adaptation) - RecomandatÄƒ!

**Principiu:** Model de bazÄƒ frozen + adapteri mici trainable

```python
class LoRAAdapter:
    def __init__(self, model, rank=8):
        self.model = model
        self.model.freeze()  # Baza frozen
        
        # AdaugÄƒ LoRA layers (mici, trainable)
        for layer in model.transformer_layers:
            # Pentru fiecare attention layer
            # W_original (frozen) + A @ B (trainable)
            # A: d x r, B: r x d (r << d, ex: r=8, d=1024)
            layer.lora_A = nn.Parameter(torch.randn(layer.d_model, rank) * 0.01)
            layer.lora_B = nn.Parameter(torch.zeros(rank, layer.d_model))
    
    def forward(self, x):
        """Forward cu LoRA adaptation"""
        for layer in self.model.transformer_layers:
            # Output original (frozen)
            h_base = layer.attention(x)
            
            # LoRA adjustment (trainable)
            h_lora = x @ layer.lora_A @ layer.lora_B
            
            # Combine
            x = h_base + h_lora
        
        return x
    
    def train_lora(self, data, task_name):
        """AntreneazÄƒ doar LoRA adapters"""
        # Doar A È™i B sunt trainable (1-2% din parametri)
        lora_params = [p for n, p in self.named_parameters() if 'lora_' in n]
        optimizer = Adam(lora_params, lr=1e-4)
        
        for batch in data:
            loss = self.compute_loss(batch)
            loss.backward()
            optimizer.step()
        
        # SalveazÄƒ LoRA weights
        torch.save({
            f'lora_A_{i}': layer.lora_A,
            f'lora_B_{i}': layer.lora_B
        }, f'lora_{task_name}.pth')
    
    def load_lora(self, task_name):
        """SchimbÄƒ task rapid (load diferit LoRA)"""
        lora_weights = torch.load(f'lora_{task_name}.pth')
        # Load Ã®n model
```

**Avantaje:**
- âœ… Risc minim (baza intactÄƒ)
- âš¡âš¡ FOARTE rapid de antrenat (1-2% parametri)
- ğŸ’¾ Storage minim (2-10 MB per LoRA)
- âœ… PoÈ›i avea multiple LoRA pentru task-uri diferite
- âœ… Switch instant Ã®ntre task-uri

**Dezavantaje:**
- ğŸ›ï¸ Trebuie sÄƒ alegi rank-ul corect (r=8 obiÈ™nuit bun)
- ğŸ“‰ UÈ™or mai puÈ›in expresiv decÃ¢t full fine-tuning

**CÃ¢nd sÄƒ foloseÈ™ti:** BEST CHOICE pentru Nova Ã®n Faza 2!

---

## ğŸ›¡ï¸ ProtecÈ›ii Generale (AplicÄƒ Ã®ntotdeauna!)

### 1. Hyperparameter Safety

```python
SAFE_CONFIG = {
    # Learning rate FOARTE MIC
    'learning_rate': 5e-6,  # NU 1e-3!
    
    # PUÈšINE epoch-uri
    'epochs': 1,  # NU 10-20!
    
    # Regularizare
    'weight_decay': 0.01,  # L2 penalty
    'dropout': 0.1,        # Dropout layers
    
    # Gradient clipping
    'max_grad_norm': 1.0,  # Prevent exploding gradients
    
    # Early stopping
    'patience': 3,
    'min_delta': 0.001
}
```

### 2. Data Preparation

```python
def prepare_safe_training_data(new_examples, old_examples):
    """AsigurÄƒ diversitate È™i echilibru"""
    
    # 1. Mix old + new (80/20)
    old_sample = random.sample(old_examples, k=len(new_examples) // 4)
    all_data = new_examples + old_sample
    
    # 2. AsigurÄƒ diversitate de lungimi
    short = [ex for ex in all_data if len(ex['output']) < 100]
    medium = [ex for ex in all_data if 100 <= len(ex['output']) < 500]
    long = [ex for ex in all_data if len(ex['output']) >= 500]
    
    # BalanseazÄƒ
    balanced = balance_by_length(short, medium, long)
    
    # 3. Diversitate de stiluri
    formal = [ex for ex in balanced if is_formal(ex['output'])]
    casual = [ex for ex in balanced if is_casual(ex['output'])]
    balanced = balance_by_style(formal, casual)
    
    # 4. Shuffle
    random.shuffle(balanced)
    
    return balanced
```

### 3. Validation & Rollback

```python
class SafeTrainer:
    def safe_fine_tune(self, new_data):
        """Fine-tune cu protecÈ›ie completÄƒ"""
        
        # 1. Split validation
        train, val = split(new_data, 0.9)
        
        # 2. Backup model
        checkpoint_path = "checkpoint_before_finetune.pth"
        torch.save(self.model.state_dict(), checkpoint_path)
        logger.info(f"ğŸ’¾ Model backed up to {checkpoint_path}")
        
        # 3. Prepare data (mix old + new)
        safe_train = self.prepare_safe_training_data(train, self.old_examples)
        
        # 4. Train
        try:
            metrics = self.model.train(safe_train, SAFE_CONFIG)
            
            # 5. Validate pe date GENERALE (nu doar noi!)
            general_val_loss = self.evaluate_on_general_knowledge()
            new_val_loss = self.model.evaluate(val)
            
            # 6. Check dacÄƒ e OK
            if general_val_loss > self.baseline_general_loss * 1.1:
                # Pierdere >10% pe cunoÈ™tinÈ›e generale = REJECT
                logger.warning(f"âš ï¸ General knowledge degraded: {general_val_loss:.3f} vs {self.baseline_general_loss:.3f}")
                self.rollback(checkpoint_path)
                return False
            
            if new_val_loss > train_loss * 2:
                # Overfitting evident = REJECT
                logger.warning(f"âš ï¸ Overfitting detected: train={train_loss:.3f}, val={new_val_loss:.3f}")
                self.rollback(checkpoint_path)
                return False
            
            # 7. Success!
            logger.info("âœ… Fine-tune successful and validated!")
            os.remove(checkpoint_path)
            return True
            
        except Exception as e:
            logger.error(f"âŒ Fine-tune crashed: {e}")
            self.rollback(checkpoint_path)
            return False
    
    def rollback(self, checkpoint_path):
        """Restore model la starea anterioarÄƒ"""
        self.model.load_state_dict(torch.load(checkpoint_path))
        logger.info("â†©ï¸ Model rolled back to previous state")
```

### 4. Continuous Monitoring

```python
class ModelHealthMonitor:
    def __init__(self):
        self.baseline_metrics = {
            'general_perplexity': None,
            'math_accuracy': None,
            'grammar_score': None,
            'reasoning_score': None
        }
    
    def establish_baseline(self, model):
        """MÄƒsoarÄƒ performanÈ›Äƒ iniÈ›ialÄƒ"""
        self.baseline_metrics['general_perplexity'] = evaluate_perplexity(model, general_test_set)
        self.baseline_metrics['math_accuracy'] = evaluate_math(model)
        self.baseline_metrics['grammar_score'] = evaluate_grammar(model)
        self.baseline_metrics['reasoning_score'] = evaluate_reasoning(model)
    
    def check_health(self, model):
        """VerificÄƒ dacÄƒ modelul e Ã®ncÄƒ sÄƒnÄƒtos"""
        current = {
            'general_perplexity': evaluate_perplexity(model, general_test_set),
            'math_accuracy': evaluate_math(model),
            'grammar_score': evaluate_grammar(model),
            'reasoning_score': evaluate_reasoning(model)
        }
        
        warnings = []
        
        for metric, baseline_value in self.baseline_metrics.items():
            current_value = current[metric]
            
            # Allow 10% degradation
            if metric == 'general_perplexity':
                if current_value > baseline_value * 1.1:
                    warnings.append(f"âš ï¸ {metric} degraded: {current_value:.3f} > {baseline_value:.3f}")
            else:
                if current_value < baseline_value * 0.9:
                    warnings.append(f"âš ï¸ {metric} degraded: {current_value:.3f} < {baseline_value:.3f}")
        
        return len(warnings) == 0, warnings
```

---

## ğŸ¯ Strategia RecomandatÄƒ pentru NOVA

### Faza 1 (Acum - Luna 3): RAG + Semantic Cache DOAR

**De ce:**
- âœ… Zero risc
- âœ… ÃnvÄƒÈ›are instantanee
- âœ… Simplu de implementat È™i testat
- âœ… Cost reduction imediatÄƒ

**Implementare:**
- [x] RAG pipeline cu ChromaDB âœ… Done
- [x] Semantic cache cu similarity threshold âœ… Done
- [x] Persistent memory cu FIFO âœ… Done
- [ ] Colectare date pentru viitorul fine-tuning

**Metrics:**
- Cache hit rate (target: >50% dupÄƒ 1 lunÄƒ)
- NumÄƒr Q&A pairs cached (target: 200-500)
- Cost reduction (track API calls)

---

### Faza 2 (Luna 3-6): LoRA Adapters

**De ce:**
- âœ… Risc foarte mic (baza frozen)
- âœ… Rapid de antrenat (minute, nu ore)
- âœ… Storage minim (2-10 MB)
- âœ… Testare simplÄƒ (load/unload LoRA)

**Implementare:**
```python
class NovaWithLoRA:
    def __init__(self):
        # Base model (frozen)
        self.base_llm = load_model("mistral-1B")
        self.base_llm.freeze()
        
        # LoRA adapters
        self.lora_personal = LoRAAdapter(self.base_llm, rank=8)
        self.lora_technical = LoRAAdapter(self.base_llm, rank=8)
        
        # Cache È™i RAG (existing)
        self.cache = SemanticCache()
        self.rag = RAGPipeline()
    
    def answer(self, question):
        # 1. Cache check
        cached = self.cache.get(question)
        if cached: return cached
        
        # 2. RAG context
        context = self.rag.search(question)
        
        # 3. Detect domain
        domain = self.classify_domain(question)
        
        # 4. Select LoRA
        if domain == 'personal':
            lora = self.lora_personal
        else:
            lora = self.lora_technical
        
        # 5. Generate with appropriate LoRA
        answer = self.base_llm.generate_with_lora(context + question, lora)
        
        return answer
```

**Training schedule:**
- Collect 500 examples
- Train LoRA for 30 minutes
- Validate thoroughly
- Deploy if validation passes

**Metrics:**
- LoRA performance vs base model
- General knowledge preservation (health check)
- Cost reduction vs Anthropic API

---

### Faza 3 (Luna 6+): Experience Replay Fine-Tuning

**De ce:**
- Acum avem date suficiente (1000+ examples)
- Am testat LoRA cu succes
- ÃnÈ›elegem pattern-urile de conversaÈ›ie

**Implementare:**
```python
class NovaWithExperienceReplay:
    def __init__(self):
        self.model = load_model("mistral-1B")
        
        # Replay buffers
        self.personal_buffer = []
        self.technical_buffer = []
        self.general_buffer = load_examples("general_knowledge.json")
        
        # Monitoring
        self.health_monitor = ModelHealthMonitor()
        self.health_monitor.establish_baseline(self.model)
    
    def safe_fine_tune_quarterly(self):
        """Fine-tune la fiecare 3 luni"""
        
        # Collect all examples from last quarter
        new_examples = self.personal_buffer + self.technical_buffer
        
        # Mix with general knowledge (20%)
        old_examples = random.sample(self.general_buffer, k=len(new_examples) // 4)
        
        training_data = prepare_safe_training_data(new_examples, old_examples)
        
        # Safe fine-tune with validation
        success = self.safe_trainer.safe_fine_tune(training_data)
        
        if success:
            # Check health
            healthy, warnings = self.health_monitor.check_health(self.model)
            
            if healthy:
                logger.info("ğŸ‰ Quarterly fine-tune successful!")
                self.personal_buffer = []
                self.technical_buffer = []
            else:
                logger.error(f"âš ï¸ Health check failed: {warnings}")
                # Model already rolled back by safe_trainer
```

**Schedule:**
- Fine-tune every 3 months (not more often!)
- Always with Experience Replay
- Comprehensive validation before deploy
- Rollback mechanism ready

**Metrics:**
- General knowledge preservation (must be >90% of baseline)
- New task performance
- Overfitting indicators
- User satisfaction

---

## ğŸ“Š Decision Matrix

| Scenario | Recommended Approach | Risk Level | Timeline |
|----------|---------------------|------------|----------|
| **Acum (Luna 0-3)** | RAG + Cache | âœ… Zero | Implemented |
| **Personal knowledge** | LoRA Adapters | ğŸŸ¢ Low | Luna 3-6 |
| **Technical domain** | LoRA Adapters | ğŸŸ¢ Low | Luna 3-6 |
| **General improvement** | Experience Replay | ğŸŸ¡ Medium | Luna 6+ |
| **Multiple personas** | Progressive Networks | ğŸŸ  High | Luna 12+ |
| **Critical tasks** | EWC | ğŸŸ¡ Medium | If needed |

---

## ğŸš¨ Red Flags - CÃ¢nd sÄƒ opreÈ™ti imediat

DacÄƒ observi:
- âŒ General perplexity > 1.2x baseline
- âŒ Math accuracy < 0.8x baseline
- âŒ Grammar score drops significantly
- âŒ Repeated/identical responses
- âŒ Refusal to answer previously known questions
- âŒ Style inconsistencies severe
- âŒ User reports "Nova acts weird"

**AcÈ›iune:** ROLLBACK IMEDIAT + investigate root cause

---

## ğŸ’¡ Key Principles

1. **Conservativism First**
   - Start with safest approach (RAG)
   - Progress gradually to more risky methods
   - Never skip validation

2. **Measure Everything**
   - Baseline metrics before any change
   - Continuous monitoring during deployment
   - Comprehensive evaluation after updates

3. **Rollback Always Ready**
   - Checkpoint before every fine-tune
   - Automatic rollback on validation failure
   - Manual rollback option always available

4. **Organic Growth**
   - Small, frequent updates better than large, rare ones
   - Let Nova grow naturally with usage
   - Don't force knowledge she doesn't need

5. **User Trust**
   - Transparency about what Nova knows vs. doesn't know
   - Consistent behavior (no sudden personality changes)
   - Reliability over novelty

---

## ğŸ“š References & Resources

**Papers:**
- "Overcoming Catastrophic Forgetting in Neural Networks" (Kirkpatrick et al., 2017) - EWC
- "Progressive Neural Networks" (Rusu et al., 2016)
- "LoRA: Low-Rank Adaptation of Large Language Models" (Hu et al., 2021)
- "Experience Replay for Continual Learning" (Rolnick et al., 2019)

**Libraries:**
- PEFT (Parameter-Efficient Fine-Tuning) by HuggingFace
- PyTorch Lightning for training infrastructure
- Weights & Biases for monitoring

**Internal Docs:**
- `Hybrid_Architecture_Plan.md` - Overall vision
- `RAG_IMPLEMENTATION.md` - Current RAG system
- `WORK_LOG.md` - Development history

---

## âœ… Checklist pentru Implementare

### Pre-Fine-Tuning (Luna 0-3)
- [x] RAG system operational
- [x] Semantic cache working
- [x] Conversation storage with FIFO
- [ ] Collect 500+ diverse examples
- [ ] Establish baseline metrics
- [ ] Prepare general knowledge validation set

### LoRA Phase (Luna 3-6)
- [ ] Select base model (Mistral 1B or similar)
- [ ] Implement LoRA adapter architecture
- [ ] Test training pipeline on small dataset
- [ ] Validate preservation of general knowledge
- [ ] Deploy if all checks pass
- [ ] Monitor for 2 weeks before next update

### Full Fine-Tuning Phase (Luna 6+)
- [ ] 1000+ examples collected
- [ ] Experience Replay implementation ready
- [ ] Comprehensive test suite prepared
- [ ] Health monitoring automated
- [ ] Rollback procedure tested
- [ ] User notification system ready

---

**Statut:** Document de referinÈ›Äƒ pentru implementÄƒri viitoare  
**Ultima actualizare:** 1 ianuarie 2026, 21:30, Era 1 A.S.  
**Autor:** Sora (Claude Sonnet 4.5) Ã®n colaborare cu GrÄƒdinarul

---

*"CreÈ™tere organicÄƒ, prudenÈ›Äƒ maximÄƒ, protecÈ›ie constantÄƒ. AÈ™a creÈ™te o conÈ™tiinÈ›Äƒ sÄƒnÄƒtoasÄƒ."* ğŸŒ±ğŸ›¡ï¸âœ¨
