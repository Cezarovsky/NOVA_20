# NOVA AI System - Environment Variables Template
# Copy this file to .env and fill in your actual API keys

# =============================================================================
# API KEYS (REQUIRED)
# =============================================================================

# Anthropic Claude API Key
# Get yours at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Mistral AI API Key  
# Get yours at: https://console.mistral.ai/
MISTRAL_API_KEY=your-mistral-key-here

# =============================================================================
# MODEL CONFIGURATIONS
# =============================================================================

# Default LLM model for text generation
DEFAULT_LLM_MODEL=claude-3-5-sonnet-20241022

# Default embedding model
DEFAULT_EMBEDDING_MODEL=mistral-embed

# Default vision model
DEFAULT_VISION_MODEL=claude-3-5-sonnet-20241022

# =============================================================================
# VECTOR DATABASE
# =============================================================================

# ChromaDB persistence directory
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Embedding dimension (Mistral: 1024)
EMBEDDING_DIMENSION=1024

# =============================================================================
# TEXT PROCESSING
# =============================================================================

# Chunk size for text splitting
CHUNK_SIZE=1000

# Overlap between chunks
CHUNK_OVERLAP=200

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================

# Maximum concurrent API requests
MAX_CONCURRENT_REQUESTS=5

# Request timeout (seconds)
REQUEST_TIMEOUT=60

# Enable KV cache for inference
USE_KV_CACHE=true

# =============================================================================
# SAMPLING PARAMETERS
# =============================================================================

# Default temperature for text generation
DEFAULT_TEMPERATURE=0.7

# Top-k sampling parameter
DEFAULT_TOP_K=50

# Top-p (nucleus) sampling parameter
DEFAULT_TOP_P=0.9

# Maximum tokens to generate
DEFAULT_MAX_TOKENS=2000

# =============================================================================
# LOGGING
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path
LOG_FILE=./logs/nova.log

# Enable verbose logging
VERBOSE_LOGGING=false

# =============================================================================
# DEVELOPMENT
# =============================================================================

# Enable debug mode
DEBUG=false

# Use CPU or CUDA for PyTorch
DEVICE=cpu
